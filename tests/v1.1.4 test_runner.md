# Test Runner

A single script to execute the v1.1.4 test plan cases for both **CLI** and **API**.
Uses environment variables (via `.env`) for your API URL and CSV inputs.

---

## 1. Overview of `test_runner.sh`

The `test_runner.sh` script automates running predefined CLI and API test cases.  
Usage:
```bash
./test_runner.sh <CASE_ID|all|list> [--dry-run]
```
- **CASE_ID**: One of the listed tests (C1–C7, A1–A8)  
- `all`: Runs all tests sequentially  
- `list`: Prints available tests and environment variable info  
- `--dry-run`: Shows commands without executing them

Environment variables are read from `.env` (or directly from your shell). These include:
- `API_URL`: API endpoint base URL (e.g., https://your-app.vercel.app/api/overlap)
- `PACE_CSV_URL`: URL to pace data CSV
- `OVERLAPS_CSV_URL`: URL to overlaps CSV
- `LOCAL_PACE_CSV`: Local path to pace CSV
- `LOCAL_OVERLAPS_CSV`: Local path to overlaps CSV
- `START_TIMES_JSON`: JSON for start times (e.g., '{"Full":420,"10K":440,"Half":460}')
- `TIME_WINDOW`: Time window in seconds
- `STEP_KM`: Step size in km
- `RANK_BY`: Ranking metric (`peak_ratio`, `intensity`)
- `VERBOSE`: true/false

---

## 2. Editing `.env`

If `.env.sample` is hidden (macOS Finder hides dotfiles), you can:
```bash
cp .env.sample .env
```
Edit `.env` using a terminal editor (`nano .env`) or enable Finder to show hidden files with:
```bash
defaults write com.apple.finder AppleShowAllFiles YES
killall Finder
```

---

## 3. CLI Test Cases (C1–C7)

| ID  | Description | Inputs | Expected Result |
|-----|-------------|--------|-----------------|
| **C1** | All segments, verbose, export | Local CSVs, `--verbose`, `--export-summary` | Detailed segment output; summary CSV created; exit 0 |
| **C2** | Subset segments (valid) | `--segments "<valid segment>"` | Only specified segment processed; matches API output |
| **C3** | Rank by intensity | `--rank-by intensity` | Output sorted by intensity; values match API |
| **C4** | Minimal run (quiet) | No `--verbose`, minimal args | Summary only; no verbose output |
| **C5** | Bad request: missing overlaps arg | Missing overlaps CSV arg | CLI error: missing required argument; exit non-zero |
| **C6** | Bad segment spec | Invalid segment name | CLI error: "No such segment in overlaps"; exit non-zero |
| **C7** | Back-compat alias `--step` | Uses `--step` instead of `--step-km` | Runs successfully; step size applied |

---

## 4. API Test Cases (A1–A8)

| ID  | Description | Inputs | Expected Result |
|-----|-------------|--------|-----------------|
| **A1** | All segments | `paceCsv`, `overlapsCsv`, `startTimes`, `timeWindow`, `stepKm`, `verbose`, `rankBy` | HTTP 200; all segments processed; performance headers present |
| **A2** | Subset segments (valid) | Adds `segments: ["<valid segment>"]` | Only specified segment in output; matches CLI |
| **A3** | Rank by intensity | `rankBy: "intensity"` | Segments ranked by intensity; values match CLI |
| **A4** | Missing required field | No `paceCsv` | HTTP 400 or 500; error about missing field |
| **A5** | Bad segments (invalid) | `segments: ["Full:99.00-100.00"]` | HTTP 200; warning about no matching valid segments |
| **A6** | Step size alias `step_km` | `step_km` instead of `stepKm` | Runs successfully; step applied |
| **A7** | JSON parse error | Broken JSON payload | HTTP 500; FUNCTION_INVOCATION_FAILED |
| **A8** | Performance header present | Normal run; check headers | HTTP 200; contains `x-compute-seconds` |

---

## 5. Running Tests

Run a specific test:
```bash
./test_runner.sh C1
```
Run all tests:
```bash
./test_runner.sh all
```
List tests:
```bash
./test_runner.sh list
```

---

## 6. Expected Outputs and Logs

- All runs log to `results/test_runs/<timestamp>_<CASE_ID>.log`
- API tests show HTTP status, headers, and response body
- CLI tests show stdout/stderr output
- Compare CLI vs API results to verify parity
